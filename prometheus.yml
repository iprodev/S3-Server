# Prometheus Configuration for S3 Storage System

global:
  scrape_interval: 15s      # Scrape targets every 15 seconds
  evaluation_interval: 15s  # Evaluate rules every 15 seconds
  external_labels:
    cluster: 's3-storage'
    environment: 'production'

# Alertmanager configuration (optional)
# alerting:
#   alertmanagers:
#     - static_configs:
#         - targets:
#           - 'alertmanager:9093'

# Load rules once and periodically evaluate them
# rule_files:
#   - "alerts.yml"

# Scrape configurations
scrape_configs:
  # S3 Gateway metrics
  - job_name: 's3-gateway'
    static_configs:
      - targets: ['gateway:9091']
        labels:
          service: 'gateway'
          role: 'api'
    
    # Scrape interval override (optional)
    scrape_interval: 10s
    scrape_timeout: 5s
    
    # Metrics path
    metrics_path: /metrics
    
    # Relabeling (optional)
    relabel_configs:
      - source_labels: [__address__]
        target_label: instance
        regex: '([^:]+)(?::\d+)?'
        replacement: '${1}'

  # Additional gateway instances (if running multiple)
  # - job_name: 's3-gateway-ha'
  #   static_configs:
  #     - targets: 
  #       - 'gateway1:9091'
  #       - 'gateway2:9091'
  #       - 'gateway3:9091'

  # Storage nodes (optional - if nodes expose metrics)
  # - job_name: 's3-nodes'
  #   static_configs:
  #     - targets:
  #       - 'node1:9091'
  #       - 'node2:9091'
  #       - 'node3:9091'

  # Prometheus self-monitoring
  - job_name: 'prometheus'
    static_configs:
      - targets: ['localhost:9090']
        labels:
          service: 'prometheus'

# Storage configuration
storage:
  tsdb:
    path: /prometheus
    retention:
      time: 15d          # Keep metrics for 15 days
      size: 50GB         # Or 50GB max, whichever comes first

# Remote write (optional - for long-term storage)
# remote_write:
#   - url: 'http://remote-storage:9009/api/v1/write'
#     queue_config:
#       capacity: 10000
#       max_shards: 50
#       min_shards: 1
